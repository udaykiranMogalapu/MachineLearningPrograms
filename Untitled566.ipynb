{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udaykiranMogalapu/MachineLearningPrograms/blob/main/Untitled566.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A-oJo0jHKQX"
      },
      "outputs": [],
      "source": [
        "SET-1\n",
        "a. To display all arithmetic operations using NumPy arrays.\n",
        "Ans: import numpy as np\n",
        "z1=np.array([[1,2,3],[4,5,6]])\n",
        "z2=np.array([[7,8,9],[10,11,12]])\n",
        "zadd=np.add(z1,z2)\n",
        "print(zadd)\n",
        "zsub=np.subtract(z1,z2)\n",
        "print(zsub)\n",
        "zmul=np.multiply(z1,z2)\n",
        "print(zmul)\n",
        "zdiv=np.divide(z1,z2)\n",
        "print(zdiv)\n",
        "zfdiv=np.floor_divide(z1,z2)\n",
        "print(zfdiv)\n",
        "zmod=np.mod(z1,z2)\n",
        "print(zmod)\n",
        "zpow=np.power(z1,z2)\n",
        "print(zpow)\n",
        "z1neg=np.negative(z1)\n",
        "print(z1neg)\n",
        "print(\"--------------------------------------------------------\")\n",
        "b. To Perform the data preprocessing techniques on the dataset (Rescale,\n",
        "standardize,normalize, binarize )\n",
        "Ans: import pandas as pd\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn import preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array = df.values\n",
        "# separate array into input and output components\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "set_printoptions(precision=3)\n",
        "# Rescale data (between 0 and 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Standardize data (0 mean, 1 stdev)\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Normalize data (length of 1)\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "print(normalizedX[0:5,:])\n",
        "# binarization\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "print(binaryX[0:5,:])\n",
        "print(\"--------------------------------------------------------\")\n",
        "c. Analyze the sample data by plotting a uni-variate histogram plot, and a\n",
        "correlation matrix plot.\n",
        "Ans: #Histogram plot\n",
        "import matplotlib.pyplot as plt\n",
        "df.hist()\n",
        "plt.rcParams['figure.figsize']=[40,30];\n",
        "plt.show()\n",
        "#correlation matrix plot\n",
        "correlations=df.corr()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
        "fig.colorbar(cax)\n",
        "ticks = np.arange(0,9,1)\n",
        "names=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','\n",
        "BMI','DiabetesPedigreeFunction','Age','Outcome']\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_yticklabels(names)\n",
        "plt.show()\n",
        "print(\"--------------------------------------------------------\")\n",
        "d. Split the data into Train and Test Sets of Pima Indians dataset into\n",
        "67%,33% respectively and implement Logistic Regression model.\n",
        "Ans: from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "test_size = 0.33\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "test_size=test_size,random_state=12)\n",
        "model = LogisticRegression(solver='lbfgs',max_iter=500)\n",
        "model.fit(X_train, Y_train)\n",
        "e. Evaluate the performance of the algorithm by calculating Regression\n",
        "Metrics(Mean Absolute Error, Mean Squared Error and RSquared)\n",
        "Ans: #Cross Validation Regression MAE\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"MAE:\",results.mean(), results.std())\n",
        "#Cross Validation Regression MSE\n",
        "scoring = 'neg_mean_squared_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"MSE:\",-1*results.mean(), results.std())\n",
        "#Cross Validation Regression R^2\n",
        "scoring = 'r2'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"R^2:\",results.mean(), results.std())\n",
        "SET-2\n",
        "a.Create data frame and access the data in a Pandas data frame.\n",
        "Ans:import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array=df.values\n",
        "print(df)\n",
        "print(df.shape)\n",
        "print(\"First row:\", array[0])\n",
        "print(\"Last row:\",array[-1])\n",
        "print(\"Specific row and col:\",array[0, 2])\n",
        "print(\"Whole col: \",array[:, 2])\n",
        "print(\"--------------------------------------------------------\")\n",
        "b.To Perform the data preprocessing techniques on the dataset (Rescale,\n",
        "standardize,normalize, binarize )\n",
        "Ans:from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn import preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array = df.values\n",
        "# separate array into input and output components\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "set_printoptions(precision=3)\n",
        "# Rescale data (between 0 and 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Standardize data (0 mean, 1 stdev)\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Normalize data (length of 1)\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "print(normalizedX[0:5,:])\n",
        "# binarization\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "print(binaryX[0:5,:])\n",
        "print(\"--------------------------------------------------------\")\n",
        "c.Analyze the sample data by plotting a uni-variate density plot and\n",
        "multivariate scatter plot.\n",
        "Ans: #Density plot\n",
        "import matplotlib.pyplot as plt\n",
        "df.plot(kind='density', subplots=True, layout=(3,3), sharex=False)\n",
        "plt.show()\n",
        "#Scatter plot\n",
        "from pandas.plotting import scatter_matrix\n",
        "scatter_matrix(df)\n",
        "plt.show()\n",
        "print(\"--------------------------------------------------------\")\n",
        "d.To implement Linear Discriminant Analysis (LDA) on the dataset\n",
        "Ans:from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "model = LinearDiscriminantAnalysis()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n",
        "print(\"--------------------------------------------------------\")\n",
        "e.Evaluate the performance of the algorithm by calculating Regression\n",
        "Metrics(Mean Absolute Error, Mean Squared Error and RSquared)\n",
        "Ans:#Cross Validation Regression MAE\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"MAE:\",results.mean(), results.std())\n",
        "#Cross Validation Regression MSE\n",
        "scoring = 'neg_mean_squared_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"MSE:\",-1*results.mean(), results.std())\n",
        "#Cross Validation Regression R^2\n",
        "scoring = 'r2'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"R^2:\",results.mean(), results.std())\n",
        "SET-3\n",
        "a.To implement Feature Selection Techniques on a sample data set.\n",
        "b.Program to implement Univariate Selection using chi-squared (chi2)\n",
        "statistical test for non-negative features to select 4 of the best\n",
        "features.\n",
        "Ans:import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "df=pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array=df.values\n",
        "X=array[:,0:8]\n",
        "Y=array[:,8]\n",
        "test = SelectKBest(score_func=chi2, k=4)\n",
        "fit = test.fit(X, Y)\n",
        "np.set_printoptions(precision=3)\n",
        "print(fit.scores_)\n",
        "features = fit.transform(X)\n",
        "print(features[0:5,:])\n",
        "print(\"--------------------------------------------------------\")\n",
        "c.Recursive Feature Elimination RFE with the logistic regression Algorithm\n",
        "to select the top 3 features.\n",
        "Ans:from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "model = LogisticRegression(solver='lbfgs',max_iter=256)\n",
        "rfe = RFE(model, n_features_to_select=3)\n",
        "fit = rfe.fit(X, Y)\n",
        "print(\"Num Features:\",fit.n_features_)\n",
        "print(\"Selected Features:\",fit.support_)\n",
        "print(\"Feature Ranking:\", fit.ranking_)\n",
        "cols_idxs = rfe.get_support(indices=True)\n",
        "newdf=df.iloc[:,cols_idxs]\n",
        "print(list(newdf.columns))\n",
        "print(\"--------------------------------------------------------\")\n",
        "d.Principle Component Analysis PCA and select 3 principal components.\n",
        "Ans:from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=3)\n",
        "fit = pca.fit(X)\n",
        "print(\"Explained Variance:\",fit.explained_variance_ratio_)\n",
        "print(fit.components_)\n",
        "SET-4\n",
        "a.To Perform the data preprocessing techniques on the dataset (Rescale,\n",
        "standardize,normalize, binarize )\n",
        "Ans:import pandas as pd\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn import preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array = df.values\n",
        "# separate array into input and output components\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "set_printoptions(precision=3)\n",
        "# Rescale data (between 0 and 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Standardize data (0 mean, 1 stdev)\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Normalize data (length of 1)\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "print(normalizedX[0:5,:])\n",
        "# binarization\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "print(binaryX[0:5,:])\n",
        "print(\"--------------------------------------------------------\")\n",
        "b.to implement k-Nearest Neighbors.\n",
        "Ans:from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier()\n",
        "results_knn = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results_knn.mean())\n",
        "print(\"--------------------------------------------------------\")\n",
        "c. Analyze the sample data by plotting a uni-variate box plots and a\n",
        "multi-variate correlation matrix plot\n",
        "#Box plot\n",
        "Ans:import matplotlib.pyplot as plt\n",
        "df.plot(kind='box', subplots=True, layout=(3,3), sharex=False,\n",
        "sharey=False)\n",
        "plt.show()\n",
        "#correlation matrix plot\n",
        "correlations=df.corr()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
        "fig.colorbar(cax)\n",
        "ticks = np.arange(0,9,1)\n",
        "names=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','\n",
        "BMI','DiabetesPedigreeFunction','Age','Outcome']\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_yticklabels(names)\n",
        "plt.show()\n",
        "print(\"--------------------------------------------------------\")\n",
        "d.Evaluate the performance of the algorithm by Accuracy, ConfusionMatrix\n",
        ",Precision ,Recall, F-Score, AUC(Area Under the Curve)-ROC\n",
        "Ans:#Accuracy\n",
        "scoring = 'accuracy'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy:\",results.mean(), results.std())\n",
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "test_size=0.33,random_state=7)\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "print(matrix)\n",
        "#Precision\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(Y_test, predicted)\n",
        "print(\"Precision:\", precision)\n",
        "#Recall\n",
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(Y_test, predicted)\n",
        "print(\"Recall:\", recall)\n",
        "#F-score\n",
        "from sklearn.metrics import f1_score\n",
        "f1=f1_score(Y_test,predicted)\n",
        "print(\"F1 score:\", f1)\n",
        "#AUC-ROC\n",
        "scoring = 'roc_auc'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"AUC:\",results.mean(), results.std())\n",
        "SET-5\n",
        "a.To Perform the data preprocessing techniques on the dataset (Rescale,\n",
        "standardize,normalize, binarize )\n",
        "Ans:import pandas as pd\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn import preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array = df.values\n",
        "# separate array into input and output components\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "set_printoptions(precision=3)\n",
        "# Rescale data (between 0 and 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Standardize data (0 mean, 1 stdev)\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Normalize data (length of 1)\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "print(normalizedX[0:5,:])\n",
        "# binarization\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "print(binaryX[0:5,:])\n",
        "print(\"--------------------------------------------------------\")\n",
        "b.To implement Naive Bayes.\n",
        "Ans:from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "model = GaussianNB()\n",
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "results_nb = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results_nb.mean())\n",
        "print(\"--------------------------------------------------------\")\n",
        "c.Analyze the sample data by plotting a uni-variate Whisker plots and a\n",
        "multi-variate Scatter plot\n",
        "Ans:#Whisker/box plot(rendu okate mawa)\n",
        "import matplotlib.pyplot as plt\n",
        "df.plot(kind='box', subplots=True, layout=(3,3), sharex=False,\n",
        "sharey=False)\n",
        "plt.show()\n",
        "print(\"--------------------------------------------------------\")\n",
        "d.Evaluate the performance of the algorithm by Accuracy, ConfusionMatrix\n",
        ",Precision ,Recall, F-Score, AUC(Area Under the Curve)-ROC\n",
        "Ans:#Accuracy\n",
        "scoring = 'accuracy'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy:\",results.mean(), results.std())\n",
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "test_size=0.33,random_state=7)\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "print(matrix)\n",
        "#Precision\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(Y_test, predicted)\n",
        "print(\"Precision:\", precision)\n",
        "#Recall\n",
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(Y_test, predicted)\n",
        "print(\"Recall:\", recall)\n",
        "#F-score\n",
        "from sklearn.metrics import f1_score\n",
        "f1=f1_score(Y_test,predicted)\n",
        "print(\"F1 score:\", f1)\n",
        "#AUC-ROC\n",
        "scoring = 'roc_auc'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"AUC:\",results.mean(), results.std())\n",
        "SET-6\n",
        "a.To display all arithmetic operations using NumPy arrays.\n",
        "Ans:import numpy as np\n",
        "z1=np.array([[1,2,3],[4,5,6]])\n",
        "z2=np.array([[7,8,9],[10,11,12]])\n",
        "zadd=np.add(z1,z2)\n",
        "print(zadd)\n",
        "zsub=np.subtract(z1,z2)\n",
        "print(zsub)\n",
        "zmul=np.multiply(z1,z2)\n",
        "print(zmul)\n",
        "zdiv=np.divide(z1,z2)\n",
        "print(zdiv)\n",
        "zfdiv=np.floor_divide(z1,z2)\n",
        "print(zfdiv)\n",
        "zmod=np.mod(z1,z2)\n",
        "print(zmod)\n",
        "zpow=np.power(z1,z2)\n",
        "print(zpow)\n",
        "z1neg=np.negative(z1)\n",
        "print(z1neg)\n",
        "print(\"--------------------------------------------------------\")\n",
        "b.To implement Classification id3 Decision tree\n",
        "Ans:from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array = df.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "test_size = 0.33\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "test_size=0.33,random_state=12)\n",
        "model.fit(X_train, Y_train)\n",
        "prediction=model.predict(X_test)\n",
        "c.Evaluate the performance of the algorithm by Accuracy, ConfusionMatrix\n",
        ",Precision ,Recall, F-Score, AUC(Area Under the Curve)-ROC\n",
        "Ans:#Accuracy\n",
        "scoring = 'accuracy'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy:\",results.mean(), results.std())\n",
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "print(matrix)\n",
        "#Precision\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(Y_test, predicted)\n",
        "print(\"Precision:\", precision)\n",
        "#Recall\n",
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(Y_test, predicted)\n",
        "print(\"Recall:\", recall)\n",
        "#F-score\n",
        "from sklearn.metrics import f1_score\n",
        "f1=f1_score(Y_test,predicted)\n",
        "print(\"F1 score:\", f1)\n",
        "#AUC-ROC\n",
        "scoring = 'roc_auc'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"AUC:\",results.mean(), results.std())\n",
        "SET-7\n",
        "a.To Perform the data preprocessing techniques on the dataset (Rescale,\n",
        "standardize,normalize, binarize )\n",
        "Ans:import pandas as pd\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn import preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array = df.values\n",
        "# separate array into input and output components\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "set_printoptions(precision=3)\n",
        "# Rescale data (between 0 and 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Standardize data (0 mean, 1 stdev)\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Normalize data (length of 1)\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "print(normalizedX[0:5,:])\n",
        "# binarization\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "print(binaryX[0:5,:])\n",
        "print(\"--------------------------------------------------------\")\n",
        "b.To implement Support Vector Machines\n",
        "Ans:from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "model = SVC()\n",
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "results_svm = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results_svm.mean())\n",
        "print(\"--------------------------------------------------------\")\n",
        "c.Analyze the sample data by plotting a uni-variate Whisker plots and a\n",
        "multi-variate Scatter plot\n",
        "Ans:#Whisker plot\n",
        "import matplotlib.pyplot as plt\n",
        "df.plot(kind='box', subplots=True, layout=(3,3), sharex=False,\n",
        "sharey=False)\n",
        "plt.show()\n",
        "#Scatter plot\n",
        "from pandas.plotting import scatter_matrix\n",
        "scatter_matrix(df)\n",
        "plt.show()\n",
        "print(\"--------------------------------------------------------\")\n",
        "d.Evaluate the performance of the algorithm by Accuracy, ConfusionMatrix\n",
        ",Precision ,Recall, F-Score, AUC(Area Under the Curve)-ROC\n",
        "Ans:#Accuracy\n",
        "scoring = 'accuracy'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "test_size=0.33,random_state=7)\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "print(matrix)\n",
        "#Precision\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(Y_test, predicted)\n",
        "print(\"Precision:\", precision)\n",
        "#Recall\n",
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(Y_test, predicted)\n",
        "print(\"Recall:\", recall)\n",
        "#F-score\n",
        "from sklearn.metrics import f1_score\n",
        "f1=f1_score(Y_test,predicted)\n",
        "print(\"F1 score:\", f1)\n",
        "#AUC-ROC\n",
        "scoring = 'roc_auc'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"AUC:\",results.mean(), results.std())\n",
        "SET-8\n",
        "a.To display all arithmetic operations using NumPy arrays.\n",
        "Ans:import numpy as np\n",
        "z1=np.array([[1,2,3],[4,5,6]])\n",
        "z2=np.array([[7,8,9],[10,11,12]])\n",
        "zadd=np.add(z1,z2)\n",
        "print(zadd)\n",
        "zsub=np.subtract(z1,z2)\n",
        "print(zsub)\n",
        "zmul=np.multiply(z1,z2)\n",
        "print(zmul)\n",
        "zdiv=np.divide(z1,z2)\n",
        "print(zdiv)\n",
        "zfdiv=np.floor_divide(z1,z2)\n",
        "print(zfdiv)\n",
        "zmod=np.mod(z1,z2)\n",
        "print(zmod)\n",
        "zpow=np.power(z1,z2)\n",
        "print(zpow)\n",
        "z1neg=np.negative(z1)\n",
        "print(z1neg)\n",
        "print(\"--------------------------------------------------------\")\n",
        "b.To implement Random Forest algorithm\n",
        "Ans:import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "df=pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array = df.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "model = RandomForestClassifier(n_estimators=100, max_features=3)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n",
        "print(\"--------------------------------------------------------\")\n",
        "c.Evaluate the performance of the algorithm by Accuracy, ConfusionMatrix\n",
        ",Precision ,Recall, F-Score, AUC(Area Under the Curve)-ROC\n",
        "Ans:#Accuracy\n",
        "scoring = 'accuracy'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "test_size=0.33,random_state=7)\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "print(matrix)\n",
        "#Precision\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(Y_test, predicted)\n",
        "print(\"Precision:\", precision)\n",
        "#Recall\n",
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(Y_test, predicted)\n",
        "print(\"Recall:\", recall)\n",
        "#F-score\n",
        "from sklearn.metrics import f1_score\n",
        "f1=f1_score(Y_test,predicted)\n",
        "print(\"F1 score:\", f1)\n",
        "#AUC-ROC\n",
        "scoring = 'roc_auc'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"AUC:\",results.mean(), results.std())\n",
        "SET-9\n",
        "a.Create data frame and access the data in a Pandas data frame.\n",
        "Ans:import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.sample(10))\n",
        "print(df.columns)\n",
        "print(df.shape)\n",
        "print(df[10:21])\n",
        "specific_data=[df[\"Glucose\"]]\n",
        "print(specific_data)\n",
        "print(df.iloc[5])\n",
        "print(df[\"Insulin\"].value_counts())\n",
        "print(df[\"Insulin\"].sum())\n",
        "print(df[\"Insulin\"].mean())\n",
        "print(df[\"Insulin\"].median())\n",
        "print(df[\"Insulin\"].min())\n",
        "print(df[\"Insulin\"].max())\n",
        "newcols={\"BloodPressure\":\"BP\"}\n",
        "df.rename(columns=newcols,inplace=True)\n",
        "print(df)\n",
        "print(df.isnull())\n",
        "print(\"--------------------------------------------------------\")\n",
        "b.Principle Component Analysis PCA and select 3 principal components.\n",
        "Ans:from sklearn.decomposition import PCA\n",
        "array=df.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "pca = PCA(n_components=3)\n",
        "fit = pca.fit(X)\n",
        "print(\"Explained Variance:\",fit.explained_variance_ratio_)\n",
        "print(fit.components_)\n",
        "print(\"--------------------------------------------------------\")\n",
        "c.Combine Models into Ensemble Predictions on the data set using AdaBoost\n",
        "algorithm\n",
        "Ans:from sklearn.ensemble import AdaBoostClassifier\n",
        "model = AdaBoostClassifier(n_estimators=100, random_state=7)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n",
        "SET-10\n",
        "a.To Perform the data preprocessing techniques on the dataset (Rescale,\n",
        "standardize,normalize, binarize )\n",
        "Ans:import pandas as pd\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn import preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "array = df.values\n",
        "# separate array into input and output components\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "set_printoptions(precision=3)\n",
        "# Rescale data (between 0 and 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Standardize data (0 mean, 1 stdev)\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "print(rescaledX[0:5,:])\n",
        "# Normalize data (length of 1)\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "print(normalizedX[0:5,:])\n",
        "# binarization\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "print(binaryX[0:5,:])\n",
        "print(\"--------------------------------------------------------\")\n",
        "b.To implement non-linear machine learning algorithms k-Nearest Neighbors\n",
        "and Naive Bayes.\n",
        "Ans:#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier()\n",
        "results_knn = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results_knn.mean())\n",
        "#Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "model = GaussianNB()\n",
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "results_nb = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results_nb.mean())\n",
        "print(\"--------------------------------------------------------\")\n",
        "c.Evaluate the performance of the algorithm by Accuracy, ConfusionMatrix\n",
        ",Precision ,Recall, F-Score, AUC(Area Under the Curve)-ROC\n",
        "Ans:#Accuracy\n",
        "scoring = 'accuracy'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy:\",results.mean(), results.std())\n",
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "test_size=0.33,random_state=7)\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "print(matrix)\n",
        "#Precision\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(Y_test, predicted)\n",
        "print(\"Precision:\", precision)\n",
        "#Recall\n",
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(Y_test, predicted)\n",
        "print(\"Recall:\", recall)\n",
        "#F-score\n",
        "from sklearn.metrics import f1_score\n",
        "f1=f1_score(Y_test,predicted)\n",
        "print(\"F1 score:\", f1)\n",
        "#AUC-ROC\n",
        "scoring = 'roc_auc'\n",
        "aucresults = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"AUC:\",aucresults.mean(), aucresults.std())\n",
        "print(\"--------------------------------------------------------\")\n",
        "d.Analyze the performance metrics by plotting a graph\n",
        "Ans:import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F-score', 'AUC-ROC']\n",
        "scores = [results.mean(), precision, recall, f1, aucresults.mean()]\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.bar(np.arange(len(metrics)), scores)\n",
        "ax.set_xticks(np.arange(len(metrics)))\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.set_ylabel('Score')\n",
        "plt.show()"
      ]
    }
  ]
}